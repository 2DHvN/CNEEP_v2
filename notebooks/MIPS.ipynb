{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys, os\n",
    "sys.path.append('drive/MyDrive/CNEEP_v2/')\n",
    "\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "from utils.sampler import CartesianSeqSampler\n",
    "from models.CNEEP_0 import CNEEP\n",
    "from models.train import train\n",
    "from models.validate import validate\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install av",
   "id": "4e7d8851aa756c7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ],
   "id": "3e17811ba073c83b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Hyper parameters\n",
    "#\n",
    "opt = Namespace()\n",
    "opt.device = \"cpu\"\n",
    "\n",
    "# alpha-NEEP parameter\n",
    "opt.alpha   = -0.5\n",
    "# Masking Regularization parameters\n",
    "opt.lam     = 0.0\n",
    "opt.threshold = 0.01\n",
    "\n",
    "opt.positional = True\n",
    "\n",
    "opt.latent_size = 10\n",
    "\n",
    "# gradient descent parameters\n",
    "opt.n_iter = 1\n",
    "opt.train_batch_size = 500\n",
    "opt.test_batch_size = 10000\n",
    "opt.video_batch_size = 400\n",
    "opt.n_hidden = 512\n",
    "opt.lr = 1e-3\n",
    "opt.wd = 1e-5\n",
    "\n",
    "opt.record_freq = 1000\n",
    "opt.seed = 3\n",
    "\n",
    "# dataset configurations\n",
    "opt.n_layer = 4\n",
    "opt.n_channel = 32\n",
    "opt.input_shape = (144, 144)\n",
    "opt.M = 1\n",
    "opt.L = 500\n",
    "opt.seq_len = 2\n",
    "opt.time_step = 0.01\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "\n",
    "#\n",
    "# path fot results\n",
    "#\n",
    "data_folder = \"data\"\n",
    "result_folder = \"results\"\n",
    "current_result_folder = f\"{result_folder}/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}\"\n",
    "os.makedirs(current_result_folder)\n",
    "\n",
    "current_checkpoint_path = f\"{current_result_folder}/model_parameter.pth.tar\"\n",
    "\n",
    "\n",
    "if not os.path.exists(result_folder): os.makedirs(result_folder)"
   ],
   "id": "2920c66428aa4785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "#\n",
    "# Loading MIPS data (single video version)\n",
    "#\n",
    "video_frames, _, _ = torchvision.io.read_video(\n",
    "    data_folder + \"/MIPS.mp4\",\n",
    "    pts_unit='sec', start_pts=10)\n",
    "video_tensor = video_frames.permute(0, 3, 1, 2).float()\n",
    "train_video = video_tensor[:, 0, 3:147, 3:147]\n",
    "train_video = train_video.unsqueeze(0)\n",
    "train_video = train_video.unsqueeze(2)\n",
    "print(f\"Video tensor shape: {train_video.shape}\")\n",
    "mean    = torch.mean(train_video)\n",
    "std     = torch.std(train_video)\n",
    "transform = lambda x: (x - mean) / std"
   ],
   "id": "a64ea09838721be0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Building our model\n",
    "#\n",
    "model = CNEEP(opt)\n",
    "model = model.to(opt.device)\n",
    "optim = torch.optim.Adam(\n",
    "    model.parameters(), opt.lr, weight_decay=opt.wd)\n",
    "train_sampler = CartesianSeqSampler(\n",
    "    opt.M, opt.L, opt.seq_len, opt.train_batch_size, device=opt.device\n",
    ")\n",
    "test_sampler = CartesianSeqSampler(\n",
    "    opt.M, opt.L, opt.seq_len, opt.test_batch_size, device=opt.device,\n",
    "    train=False\n",
    ")"
   ],
   "id": "1b83ca7f5be12501"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Training the model\n",
    "#\n",
    "\n",
    "train_losses = []\n",
    "R_values = []\n",
    "valid_losses = []\n",
    "best_valid_loss = float('inf')\n",
    "for i in tqdm(range(1, opt.n_iter + 1)) :\n",
    "    train_loss, R_value = train(\n",
    "        opt, model, optim, train_video, train_sampler, transform\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    R_values.append(R_value)\n",
    "\n",
    "    _, _, valid_loss = validate(\n",
    "        opt, model, train_video, test_sampler, transform\n",
    "    )\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        state = {\n",
    "            'epoch': i,\n",
    "            'settings': opt.__dict__,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optim.state_dict(),\n",
    "        }\n",
    "        torch.save(state, current_checkpoint_path)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(current_checkpoint_path)['state_dict'])\n",
    "plt.plot(train_losses)\n",
    "plt.savefig(f\"{current_result_folder}/train_loss.png\")\n",
    "plt.clf()\n",
    "plt.plot(valid_losses)\n",
    "plt.savefig(f\"{current_result_folder}/valid_loss.png\")\n",
    "plt.clf()\n",
    "plt.plot(R_values)\n",
    "plt.savefig(f\"{current_result_folder}/R_values.png\")\n",
    "plt.clf()"
   ],
   "id": "de4c07db88ec6254"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# PCA study\n",
    "#\n",
    "latent_results = []\n",
    "hooks = []\n",
    "def hook_latent(module, input, output):\n",
    "    latent_results.append(output.cpu().detach().numpy())\n",
    "hooks.append(\n",
    "    model._modules.get(\"latent\")\n",
    "    .register_forward_hook(hook_latent)\n",
    ")\n",
    "test_sampler = CartesianSeqSampler(\n",
    "    1, opt.L, opt.seq_len, opt.video_batch_size,\n",
    "    device = opt.device, train=False\n",
    ")\n",
    "ent, ent_map, _ = validate(opt, model, train_video, test_sampler, transform)\n",
    "\n",
    "latent_vectors = latent_results[0] - np.mean(latent_results[0], axis = 0)\n",
    "latent_vectors = latent_vectors / np.std(latent_vectors, axis = 0)\n",
    "U, S, V = torch.pca_lowrank(torch.tensor(latent_vectors), q=opt.latent_size)\n",
    "x = U[:, 0]\n",
    "y = U[:, 1]\n",
    "color_data = U[:, 2]\n",
    "colors = (color_data - color_data.mean()) / color_data.std()\n",
    "plt.scatter(x, y, c=colors, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{current_result_folder}/PCA_sccater(0, 1, 2).png\")\n",
    "plt.clf()\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(S)"
   ],
   "id": "6f9cbf57fc0edc4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Visualizing results\n",
    "#\n",
    "\n",
    "# animation\n",
    "ent_map_normalized = (ent_map - ent_map.min()) / (ent_map.max() - ent_map.min())\n",
    "train_video_np = train_video.clone().squeeze(0).squeeze(1).cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(train_video_np[0], cmap='gray', animated=True)\n",
    "overlay = ax.imshow(ent_map_normalized[0], cmap='viridis', alpha=0.5, animated=True)\n",
    "\n",
    "def update(frame):\n",
    "    im.set_array(train_video_np[frame])\n",
    "    overlay.set_array(ent_map_normalized[frame])\n",
    "    return [im, overlay]\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(ent_map), blit=True)\n",
    "ani.save(f\"{current_result_folder}/ent_map_animation.mp4\", fps=10)\n",
    "plt.clf()\n",
    "\n",
    "# mean local EP density\n",
    "mean_map = ent_map.mean(axis=0)\n",
    "plt.imshow(mean_map, cmap='viridis')\n",
    "plt.colorbar(label='Mean Local EP Density')\n",
    "plt.title('Mean Local EP Density Map')\n",
    "plt.savefig(f\"{current_result_folder}/mean_map.png\")\n",
    "plt.clf()"
   ],
   "id": "5b267392ba5a636c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89268bfd8554dd70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f0d52cc4446851a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
