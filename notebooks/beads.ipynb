{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys, os\n",
    "sys.path.append('drive/MyDrive/CNEEP_v2/')\n",
    "sys.path.append('drive/MyDrive/CNEEP_v2/data/beads')\n",
    "\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "from utils.sampler import CartesianSeqSampler\n",
    "from models.train import train\n",
    "from models.validate import validate\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Hyper parameters\n",
    "#\n",
    "opt = Namespace()\n",
    "opt.device = \"cuda\"\n",
    "\n",
    "opt.N = 2\n",
    "\n",
    "# alpha-NEEP parameter\n",
    "opt.alpha   = -0.5\n",
    "# Masking Regularization parameters\n",
    "opt.lam     = 0.0\n",
    "opt.threshold = 0.01\n",
    "\n",
    "opt.positional = True\n",
    "\n",
    "opt.latent_size = 10\n",
    "\n",
    "# gradient descent parameters\n",
    "opt.n_iter = 200\n",
    "opt.train_batch_size = 1024\n",
    "opt.test_batch_size = 4096\n",
    "opt.video_batch_size = 512\n",
    "opt.n_hidden = 512\n",
    "opt.lr = 1e-3\n",
    "opt.wd = 1e-5\n",
    "\n",
    "opt.record_freq = 1000\n",
    "opt.seed = 3\n",
    "\n",
    "# dataset configurations\n",
    "opt.n_layer = 2\n",
    "opt.n_channel = 32\n",
    "opt.cell_size = 20\n",
    "opt.input_shape = (opt.cell_size, opt.cell_size * opt.N)\n",
    "opt.M = 10\n",
    "opt.L = 1000\n",
    "opt.burn_in = 2000\n",
    "opt.seq_len = 2\n",
    "opt.time_step = 0.01\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "\n",
    "#\n",
    "# path fot results\n",
    "#\n",
    "data_folder = \"drive/MyDrive/CNEEP_v2/data\"\n",
    "result_folder = \"drive/MyDrive/CNEEP_v2/results\"\n",
    "current_result_folder = f\"{result_folder}/{datetime.now().strftime(\"Beads-%Y-%m-%d-%H%M%S\")}\"\n",
    "os.makedirs(current_result_folder)\n",
    "\n",
    "current_checkpoint_path = f\"{current_result_folder}/model_parameter.pth.tar\"\n",
    "\n",
    "\n",
    "if not os.path.exists(result_folder): os.makedirs(result_folder)"
   ],
   "id": "281cb1487a441e0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from data.beads.generate_trajectories import NBeadsModel\n",
    "from data.beads.generate_animations import generate_brownian_frames\n",
    "\n",
    "model = NBeadsModel(n_beads=opt.N, dt=opt.time_step)\n",
    "\n",
    "train_trajectories = model.generate_trajectories(opt.M, opt.L, burn_in=opt.burn_in)\n",
    "train_video_list = []\n",
    "for i in range(opt.M):\n",
    "    frames = generate_brownian_frames(train_trajectories[i], opt.cell_size)\n",
    "    train_video_list.append(frames)\n",
    "train_video = torch.tensor(np.array(train_video_list), dtype=torch.float32)[:,:,:,:,1].unsqueeze(2)\n",
    "print(train_video.shape)\n",
    "\n",
    "test_trajectories = model.generate_trajectories(opt.M, opt.L, burn_in=opt.burn_in)\n",
    "test_video_list = []\n",
    "GT_ent_list = []\n",
    "GT_ent_per_bead_list = []\n",
    "GT_heat_list = []\n",
    "\n",
    "for i in range(opt.M):\n",
    "    frames = generate_brownian_frames(test_trajectories[i], opt.cell_size)\n",
    "    test_video_list.append(frames)\n",
    "\n",
    "    # Note: These methods should exist within your NBeadsModel\n",
    "    GT_ent_list.append(model.compute_entropy_production_rate(test_trajectories[i]))\n",
    "    GT_ent_per_bead_list.append(model.compute_entropy_production_per_bead(test_trajectories[i]))\n",
    "    GT_heat_list.append(model.compute_heat_per_bead(test_trajectories[i]))\n",
    "\n",
    "test_video = torch.tensor(np.array(test_video_list), dtype=torch.float32)[:,:,:,:,1].unsqueeze(2)\n",
    "GT_ent = np.array(GT_ent_list)\n",
    "GT_ent_per_bead = np.array(GT_ent_per_bead_list)\n",
    "GT_heat = np.array(GT_heat_list)\n",
    "\n",
    "mean = torch.mean(train_video[0][0])\n",
    "std = torch.std(train_video[0][0])\n",
    "transform = lambda x: (x - mean) / (std)"
   ],
   "id": "a0a18889108cf4c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Building our model\n",
    "#\n",
    "from models.UNEEP_1P import CNEEP\n",
    "\n",
    "model = CNEEP(opt)\n",
    "model = model.to(opt.device)\n",
    "optim = torch.optim.Adam(\n",
    "    model.parameters(), opt.lr, weight_decay=opt.wd)\n",
    "train_sampler = CartesianSeqSampler(\n",
    "    opt.M, opt.L, opt.seq_len, opt.train_batch_size, device=opt.device\n",
    ")\n",
    "test_sampler = CartesianSeqSampler(\n",
    "    opt.M, opt.L, opt.seq_len, opt.test_batch_size, device=opt.device,\n",
    "    train=False\n",
    ")"
   ],
   "id": "cb113b088e30e790"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Training the model\n",
    "#\n",
    "\n",
    "train_losses = []\n",
    "R_values = []\n",
    "valid_losses = []\n",
    "best_valid_loss = float('inf')\n",
    "for i in tqdm(range(1, opt.n_iter + 1)) :\n",
    "    train_loss, R_value = train(\n",
    "        opt, model, optim, train_video, train_sampler, transform\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    R_values.append(R_value)\n",
    "\n",
    "    _, _, valid_loss = validate(\n",
    "        opt, model, test_video, test_sampler, transform\n",
    "    )\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        state = {\n",
    "            'epoch': i,\n",
    "            'settings': opt.__dict__,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optim.state_dict(),\n",
    "        }\n",
    "        torch.save(state, current_checkpoint_path)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(current_checkpoint_path)['state_dict'])\n",
    "plt.plot(train_losses)\n",
    "plt.savefig(f\"{current_result_folder}/train_loss.png\")\n",
    "plt.clf()\n",
    "plt.plot(valid_losses)\n",
    "plt.savefig(f\"{current_result_folder}/valid_loss.png\")\n",
    "plt.clf()\n",
    "plt.plot(R_values)\n",
    "plt.savefig(f\"{current_result_folder}/R_values.png\")\n",
    "plt.clf()"
   ],
   "id": "14e549b958aa888d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# R2-scatter plot\n",
    "#\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "pred_ent, _, _ = validate(opt, model, test_video, test_sampler, transform)\n",
    "plt.scatter(GT_ent.flatten(), pred_ent.flatten(), alpha=0.5)\n",
    "\n",
    "pred = pred_ent.flatten()\n",
    "ent = GT_ent.flatten()\n",
    "\n",
    "pred_rate, _, r_value, p_value, _  = stats.linregress(ent, pred)\n",
    "plt.figure(figsize=(3,3), dpi=100)\n",
    "sns.regplot(x = pred, y = pred,\n",
    "    color='C3',\n",
    "    line_kws={\n",
    "        'lw':2.0,\n",
    "        'label':'$R^2=$ %.4f' %(r_value**2)},\n",
    "    scatter_kws={\n",
    "        'color':'grey',\n",
    "        'alpha':0.03,\n",
    "        's':3,\n",
    "        'rasterized':True})\n",
    "plt.savefig(f\"{current_result_folder}/R2_plot.png\")\n"
   ],
   "id": "3e5be4e35c8cd8c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# PCA study\n",
    "#\n",
    "latent_results = []\n",
    "hooks = []\n",
    "def hook_latent(module, input, output):\n",
    "    latent_results.append(output.cpu().detach().numpy())\n",
    "hooks.append(\n",
    "    model._modules.get(\"latent\")\n",
    "    .register_forward_hook(hook_latent)\n",
    ")"
   ],
   "id": "a25f813443f36e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_sampler = CartesianSeqSampler(\n",
    "    1, opt.L, opt.seq_len, opt.video_batch_size,\n",
    "    device = opt.device, train=False)\n",
    "ent, ent_map, _ = validate(opt, model, test_video[0], test_sampler, transform)"
   ],
   "id": "c532f2c9780c7fda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "latent_vectors = latent_results[0] - np.mean(latent_results[0], axis = 0)\n",
    "latent_vectors = latent_vectors / np.std(latent_vectors, axis = 0)\n",
    "U, S, V = torch.pca_lowrank(torch.tensor(latent_vectors), q=opt.latent_size)\n",
    "x = U[:, 0]\n",
    "y = U[:, 1]\n",
    "color_data = U[:, 2]\n",
    "colors = (color_data - color_data.mean()) / color_data.std()\n",
    "plt.scatter(x, y, c=colors, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{current_result_folder}/PCA_sccater(0, 1, 2).png\")\n",
    "plt.clf()\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(S)"
   ],
   "id": "16c9d250a8d886ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Visualizing results\n",
    "#\n",
    "\n",
    "# animation\n",
    "ent_map_normalized = (ent_map - ent_map.min()) / (ent_map.max() - ent_map.min())\n",
    "test_video_np = test_video[0].clone().squeeze(0).squeeze(1).cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(test_video_np[0], cmap='gray', animated=True)\n",
    "overlay = ax.imshow(ent_map_normalized[0], cmap='viridis', alpha=0.5, animated=True)\n",
    "\n",
    "def update(frame):\n",
    "    im.set_array(test_video_np[frame])\n",
    "    overlay.set_array(ent_map_normalized[frame])\n",
    "    return [im, overlay]\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(ent_map), blit=True)\n",
    "ani.save(f\"{current_result_folder}/ent_map_animation.mp4\", fps=10)\n",
    "plt.clf()\n",
    "\n",
    "# mean local EP density\n",
    "mean_map = ent_map.mean(axis=0)\n",
    "plt.imshow(mean_map, cmap='viridis')\n",
    "plt.colorbar(label='Mean Local EP Density')\n",
    "plt.title('Mean Local EP Density Map')\n",
    "plt.savefig(f\"{current_result_folder}/mean_map.png\")\n",
    "plt.clf()"
   ],
   "id": "76bb60e2782a25c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
